{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2eef559",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import random\n",
    "from torch.utils.data import Dataset, random_split, DataLoader\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import os\n",
    "from matplotlib import cm\n",
    "import torchvision.models as models\n",
    "\n",
    "DATASET_PATH = 'data/train'\n",
    "TRAIN_CSV = 'data/train.csv'\n",
    "\n",
    "# Fix the random seed for reproducibility\n",
    "torch.manual_seed(0)\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.backends.cudnn.deterministic=True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "text_labels = {\n",
    "0:  \"Nucleoplasm\", \n",
    "1:  \"Nuclear membrane\",   \n",
    "2:  \"Nucleoli\",   \n",
    "3:  \"Nucleoli fibrillar center\" ,  \n",
    "4:  \"Nuclear speckles\",\n",
    "5:  \"Nuclear bodies\",\n",
    "6:  \"Endoplasmic reticulum\",   \n",
    "7:  \"Golgi apparatus\",\n",
    "8:  \"Peroxisomes\",\n",
    "9:  \"Endosomes\",\n",
    "10:  \"Lysosomes\",\n",
    "11:  \"Intermediate filaments\",   \n",
    "12:  \"Actin filaments\",\n",
    "13:  \"Focal adhesion sites\",   \n",
    "14:  \"Microtubules\",\n",
    "15:  \"Microtubule ends\",   \n",
    "16:  \"Cytokinetic bridge\",   \n",
    "17:  \"Mitotic spindle\",\n",
    "18:  \"Microtubule organizing center\",  \n",
    "19:  \"Centrosome\",\n",
    "20:  \"Lipid droplets\",   \n",
    "21:  \"Plasma membrane\",   \n",
    "22:  \"Cell junctions\", \n",
    "23:  \"Mitochondria\",\n",
    "24:  \"Aggresome\",\n",
    "25:  \"Cytosol\",\n",
    "26:  \"Cytoplasmic bodies\",   \n",
    "27:  \"Rods & rings\" \n",
    "}\n",
    "\n",
    "NUM_LABELS=len(text_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27e7aa63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to binary arrays\n",
    "def encode_label(label):\n",
    "    target = torch.zeros(NUM_LABELS)\n",
    "    for l in str(label).split(' '):\n",
    "        target[int(l)] = 1.\n",
    "    return target\n",
    "\n",
    "def decode_target(target, text_labels=False, threshold=0.5):\n",
    "    result = []\n",
    "    for i, x in enumerate(target):\n",
    "        if (x >= threshold):\n",
    "            if text_labels:\n",
    "                result.append(labels[i] + \"(\" + str(i) + \")\")\n",
    "            else:\n",
    "                result.append(str(i))\n",
    "    return ' '.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f670fa07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class to load the dataset\n",
    "class HumanProteinDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        self.transform = transform\n",
    "        self.root_dir = root_dir\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.loc[idx]\n",
    "        img_id, img_label = row['Id'], row['Target']\n",
    "        img = self.open_rgby(img_id)\n",
    "        # Resizes image and converts to tensor\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, encode_label(img_label)\n",
    "    \n",
    "    def open_rgby(self, id): #a function that reads RGBY image\n",
    "        colors = ['red','green','blue','yellow']\n",
    "        # merges the four filters of each id into a PIL\n",
    "        return Image.merge('RGBA', [Image.open(f\"{self.root_dir}/{id}_{f}.png\") for f in colors])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6215c8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(batch_size):\n",
    "    data = HumanProteinDataset(\n",
    "        csv_file = TRAIN_CSV,\n",
    "        root_dir= DATASET_PATH, \n",
    "        transform=transforms.Compose([transforms.Resize(256),transforms.ToTensor()])\n",
    "    )\n",
    "    # 10 percent of training data are utilized as a test set\n",
    "    test_pct = 0.1\n",
    "    test_size = int(test_pct * len(data))\n",
    "    train_size = len(data) - test_size\n",
    "\n",
    "    train_data, test_data = random_split(data, [train_size, test_size])\n",
    "    \n",
    "    train_dataloader = torch.utils.data.DataLoader(\n",
    "        train_data, \n",
    "        batch_size=batch_size,\n",
    "        shuffle=True, \n",
    "        num_workers=0\n",
    "    )\n",
    "    \n",
    "    test_dataloader = torch.utils.data.DataLoader(\n",
    "        test_data, \n",
    "        batch_size=batch_size,\n",
    "        shuffle=True, \n",
    "        num_workers=0\n",
    "    )\n",
    "    return train_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51c3076d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train NN\n",
    "def test(test_dataloader, model):\n",
    "    '''\n",
    "    This function will test the model performance using testing data.\n",
    "    DO NOT MODIFY!!\n",
    "    '''\n",
    "    with torch.no_grad():\n",
    "        accu_number = 0.0\n",
    "        for x, y in test_dataloader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            predicted_class = model(x)\n",
    "            accu_number += torch.sum(predicted_class == y)\n",
    "        print('testing accuracy: %.4f' % (accu_number/len(test_dataloader.dataset)))\n",
    "        \n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    '''\n",
    "    This function will conduct one-epoch training.\n",
    "    DO NOT MODIFY!!\n",
    "    '''\n",
    "    for x, y in dataloader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        pred = model(x)\n",
    "        loss = loss_fn(pred, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    #return loss\n",
    "        \n",
    "class Network(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = torch.nn.Sequential(\n",
    "            # Start with 4 channels due to the layering of the image merge\n",
    "            torch.nn.Conv2d(4, 32, kernel_size=3, stride =2, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            torch.nn.Conv2d(32, 64, kernel_size=3, stride =2, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            torch.nn.Conv2d(64, 128, kernel_size=3, stride =2, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            torch.nn.Conv2d(128, 256, kernel_size=3, stride =2, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            torch.nn.Flatten(), \n",
    "            torch.nn.Linear(256, 64),\n",
    "            torch.nn.ReLU(),\n",
    "#             torch.nn.Linear(1152, 28),\n",
    "#             torch.nn.ReLU(),\n",
    "            torch.nn.Linear(64, 32),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(32, 28),\n",
    "            # The sigmoid function returns multiple labels rather than just selecting one\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        pred = self.layers(x)\n",
    "        return pred\n",
    "    \n",
    "class Resnet34(torch.nn.Module):\n",
    "    # Preloaded Resnet34 network to speed up training\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network = models.resnet34(pretrained=True)\n",
    "        # weight for RGB is from Resnet34, weight for Y is set to mean(weight of RGB)\n",
    "        weight = self.network.conv1.weight.clone()\n",
    "        self.network.conv1 = torch.nn.Conv2d(4, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        with torch.no_grad():\n",
    "            self.network.conv1.weight[:,:3] = weight\n",
    "            self.network.conv1.weight[:, 3] = torch.mean(weight, dim=1)\n",
    "        # update out_features to NUM_LABELS\n",
    "        in_features = self.network.fc.in_features\n",
    "        self.network.fc = torch.nn.Linear(in_features, NUM_LABELS)\n",
    "        \n",
    "            \n",
    "    def forward(self, xb):\n",
    "        return torch.sigmoid(self.network(xb))\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b85ca17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(hyper_param):\n",
    "    #model = Resnet34().to(device)\n",
    "    model = Network().to(device)\n",
    "    train_dataloader, test_dataloader = load_data(hyper_param['batch_size'])\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = getattr(torch.optim, hyper_param['optimizer'])(\n",
    "        model.parameters(), \n",
    "        **hyper_param['optim_param'] ## keyword unpacking\n",
    "    )\n",
    "    for t in range(hyper_param['n_epochs']):\n",
    "        print(f\"Epoch {t}\", end=' ')\n",
    "        train(train_dataloader, model, loss_fn, optimizer)\n",
    "        test(test_dataloader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd699dd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 "
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "## Hyper-parameters\n",
    "hyper_param = {\n",
    "    'batch_size': 100,\n",
    "    'n_epochs':5,\n",
    "    'optimizer': 'SGD',\n",
    "    'optim_param': {\n",
    "        ## This dict should be changed according to the selection of optimizer ##\n",
    "        'lr': 0.1\n",
    "    }\n",
    "}\n",
    "\n",
    "# define an instance of neuralnetworks\n",
    "#main(model, hyper_param)\n",
    "main(hyper_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2764dbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5a9b8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
